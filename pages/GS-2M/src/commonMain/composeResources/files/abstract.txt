We propose a unified solution for mesh reconstruction and material decomposition from multi-view images based on 3D Gaussian Splatting, referred to as GS-2M. Previous works address these tasks separately and struggle to reconstruct highly reflective surfaces or rely on priors from external models to enhance the decomposition results. By contrast, our method addresses these two problems by jointly optimizing attributes relevant to the quality of rendered depth and normal under a unified framework, maintaining geometric details while being resilient to reflective surfaces. Although there are contemporary works that faithfully address these tasks together, they often employ sophisticated neural components to learn scene properties, hindering their performance at scale. To further eliminate these neural components, we propose a novel roughness supervision strategy based on multi-view photometric variation. When combined with a carefully designed loss and optimization process, GS-2M produces reconstruction results comparable to state-of-the-art methods, delivering triangle meshes and their associated material components for downstream tasks. We validate the effectiveness of our approach with widely used datasets from previous works and qualitative comparisons with state-of-the-art surface reconstruction methods.