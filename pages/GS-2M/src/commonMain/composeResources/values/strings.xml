<resources>
    <string name="gs2m_abstract">Recently, 3D Gaussian splatting (3DGS) has emerged as a resource-friendly technique for radiance fields, achieving SoTA rendering quality in novel view synthesis while enabling real-time rasterization. This has led to a new line of research to adopt 3DGS in various domains such as surface reconstruction, material decomposition, scene relighting, deformation, composition, and inverse rendering. To pick up on this thriving development of Gaussian splatting, we propose a unified solution for mesh reconstruction and material decomposition from multi-view images, referred to as GS–2M. Previous works address these tasks separately and either struggle to reconstruct highly reflective surfaces or require priors from external models to enhance the decomposition results. While there are contemporary works that faithfully address these tasks together, they often employ sophisticated multi layer perceptron to learn scene components. By contrast, our method tackles these two problems by jointly optimizing attributes relevant to the quality of rendered depth and normal under a unified framework. To eliminate sophisticated modeling of neural components, we propose a roughness supervision strategy based on multi-view photometric clues. When combined with a carefully designed loss and optimization process, GS–2M produces comparable results to state-of-the-art methods, delivering triangle meshes and their associated material components for downstream tasks. We validate the effectiveness of our approach with datasets extensively used in previous works and qualitative results showcasing its performance.</string>
</resources>